# Introduction {#intro}


**Notes**
[[lec_W1.1_Introduction_Statistical_Learning.pdf](https://liangfgithub.github.io/Notes/lec_W1.1_Introduction_Statistical_Learning.pdf)]
[[lec_W1.2_kNN_vs_LinearRegression.pdf](https://liangfgithub.github.io/Notes/lec_W1.2_kNN_vs_LinearRegression.pdf)]
[[lec_W1.2_kNN_vs_LinearRegression_figs.pdf](https://liangfgithub.github.io/Notes/lec_W1.2_kNN_vs_LinearRegression_figs.pdf)]
[[lec_W1.3_Introduction_LearningTheory.pdf](https://liangfgithub.github.io/Notes/lec_W1.3_Introduction_LearningTheory.pdf)]


**R/Python Code:**
[[Rcode_W1_SimulationStudy.html](https://liangfgithub.github.io/Rcode_W1_SimulationStudy.html)]
[[Rcode_W1_Examples_from_ESL.html](https://liangfgithub.github.io/Rcode_W1_Examples_from_ESL.html)]
[[Python_W1_SimulationStudy.html](https://liangfgithub.github.io/Python_W1_SimulationStudy.html)]


## Introduction to Statistical Learning

What is machine learning?

> In artificial intelligence,  machine learning involves some kind of 
machine (robot, computer) that modifies its behavior based on experience. For example, if a robot falls down every time it comes to a stairway, it will learn to avoid stairways. E-mail programs often learn to distinguish spam from regular e-mail. In statistics, machine learning uses statistical data to learn. 

What is data mining?

> Looking for relationships in large data sets. Observations are "baskets" of items. The goal is to see what items are associated with other items, or which items' presence implies the presence of other items. For example, at Walmart, one may realize that people who buy socks also buy beer. Then Walmart would be smart to put some beer cases near the socks, or vice versa. Or if the government is spying on everyone's e-mails, certain words (which I better not say) found together might cause the writer to be sent to Guantanamo. 

The **difference** for a statistician between supervised machine learning and regular data analysis is that in machine learning, the statistician does not care about the estimates of parameters nor hypothesis tests nor which models fit best. Rather, the focus is on finding some function that does a good job of predicting $y$ from $x$. Estimating parameters, fitting models, etc., may indeed be important parts of developing the function, but they are not the objective.


### Types of learning problems 

Generally, there are two categories:

- **Supervised learning** data consists of example $(y,x)$'s, the training data. The machine is a function built based on the data that takes in a new $x$, and produces a guess of the corresponding $y$. It is 

    - **regression** if the $y$'s are continuous, and

    - **classification** or **categorization** if the $y$'s are categories.

- **Unsupervised learning** is **clustering**. The data consists of example $x$'s, and the machine is a function that groups the $x$'s into clusters.


### Challenge of supervised learning 

### Curse of dimensionality 

### A glimpse of learning theory 

### Bias and variance tradeoff 

##  Least squares vs. nearest neighbors

### Introduction to LS and kNN 

### Simulation study with R

### Simulation study with Python

### Compute Bayes rule 

### Discussion 

